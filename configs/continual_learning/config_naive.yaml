# Configuration for Global Continual Learning with Our Hospital Data
data_path: "/n/data1/hms/dbmi/rajpurkar/lab/datasets/MAIDA-NICU/preprocessed_vish/new_annotations"

# Annotation paths
annos_dir: "/n/data1/hms/dbmi/rajpurkar/lab/datasets/MAIDA-NICU/preprocessed_vish/new_annotations/annotations_640x640_latest"
test_annos_path: '/n/data1/hms/dbmi/rajpurkar/lab/datasets/MAIDA-NICU/preprocessed_vish/new_annotations/annotations_640x640_latest/hospital-test-annotations.json'
train_annos_path: '/n/data1/hms/dbmi/rajpurkar/lab/datasets/MAIDA-NICU/preprocessed_vish/new_annotations/annotations_640x640_latest/hospital-train-annotations.json'

# Output directory (global_CL will be appended automatically by the code)
output_path: '/n/data1/hms/dbmi/rajpurkar/lab/datasets/MAIDA-NICU/preprocessed_vish/run_CL/outputs'

# Model configuration
model_type: "hospitals-only"  # Use our hospital data

# Simulation settings
number_of_simulation: 50  # Number of different random hospital orderings to test
skip_simulation: 0       # Start from simulation 0

# Continual learning method
update_method: 'naive'   # Simple continual learning (alternatives: 'ewc', 'rehearsal')
update_order: 'global_sequential'  # Process hospitals sequentially

# Evaluation strategy
eval_current_hospital_only: true  # Only evaluate on current hospital (deployment-focused evaluation)

# Model settings
batch_size: 32
# learning_rate: 0.0001
# num_epochs_per_hospital: 10  # How many epochs to train on each hospital

# Wandb tracking (disabled to allow running from different accounts without authentication)
use_wandb: false  # Set to true if you have wandb configured and want tracking
wandb_project_name: 'hospital-continual-learning'

# Advanced settings
# has_L2_init: false  # Whether to use L2 regularization initialization 